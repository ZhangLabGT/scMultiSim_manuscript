{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6241c9-bde1-49b4-9244-2f4d302edb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "# path to SpaOTsc\n",
    "sys.path.append('/home/SpaOTsc')\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "from spaotsc import SpaOTsc\n",
    "from sklearn.metrics import matthews_corrcoef, average_precision_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import binarize, normalize\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy import sparse\n",
    "import seaborn as sns\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e352ad-26f8-4426-b5ac-a2fe054cae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pathway(root_dir):\n",
    "    file_name = 'noise_cc_interactions'\n",
    "    lrpair_name = 'lrpair.csv'\n",
    "    pathway_name = 'pathway.csv'\n",
    "\n",
    "    data_large = pd.read_csv(os.path.join(root_dir, 'cci.csv'))\n",
    "    grn_data = pd.read_csv(os.path.join(root_dir, 'grn.csv'))\n",
    "    # * L-R pairs\n",
    "    filtered = data_large[['ligand', 'receptor']]\n",
    "    filtered['species'] = 'Human'\n",
    "    filtered.index = range(1, filtered.shape[0] + 1)\n",
    "    filtered.drop_duplicates().to_csv(os.path.join(root_dir, lrpair_name))\n",
    "    print('finish lrpair', os.path.join(root_dir, lrpair_name))\n",
    "\n",
    "    # * pathway\n",
    "    pathway = grn_data[['regulator', 'target']]\n",
    "    pathway = pathway.rename(columns={'regulator': 'src', 'target': 'dest'})\n",
    "    pathway['pathway'] = 'Various types of N-glycan biosynthesis'\n",
    "    pathway['source'] = 'KEGG'\n",
    "    pathway['type'] = 'Process(missing)'\n",
    "    pathway['src_tf'] = 'YES'\n",
    "    pathway['dest_tf'] = 'YES'\n",
    "    pathway.loc[pathway['dest'].str.slice(4).astype(int) >= 54, 'dest_tf'] = 'NO'\n",
    "    pathway['species'] = 'Human'\n",
    "    pathway.index = range(1, pathway.shape[0] + 1)\n",
    "    pathway.to_csv(os.path.join(root_dir, pathway_name))\n",
    "    print('finish pathway', os.path.join(root_dir, pathway_name))\n",
    "    \n",
    "def self_pcc_mat(x, progress=False):\n",
    "    x_minus_mu = np.empty_like(x)\n",
    "    for i in range(x.shape[0]):\n",
    "        x_minus_mu[i,:] = x[i,:] - np.mean(x[i,:])\n",
    "    x_std = np.empty([x.shape[0]], float)\n",
    "    for i in range(x.shape[0]):\n",
    "        x_std[i] = np.linalg.norm(x_minus_mu[i,:])\n",
    "        if x_std[i] == 0: x_std[i] = 1\n",
    "    pmat = np.ones( [x.shape[0], x.shape[0]], float )\n",
    "    for i in range(x.shape[0]-1):\n",
    "        for j in range(i+1, x.shape[0]):\n",
    "            c = np.dot(x_minus_mu[i,:], x_minus_mu[j,:]) / (x_std[i]*x_std[j])\n",
    "            pmat[i,j] = c; pmat[j,i] = c\n",
    "    return pmat\n",
    "\n",
    "def get_mcc(true_labels, pred_labels):\n",
    "    TP = np.sum(np.logical_and(pred_labels == 1, true_labels == 1))\n",
    "    TN = np.sum(np.logical_and(pred_labels == 0, true_labels == 0))\n",
    "    FP = np.sum(np.logical_and(pred_labels == 1, true_labels == 0))\n",
    "    FN = np.sum(np.logical_and(pred_labels == 0, true_labels == 1))\n",
    "    mcc = (TP * TN) - (FP * FN)\n",
    "    denom = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    if denom==0:\n",
    "        return 0\n",
    "    return mcc / denom\n",
    "\n",
    "def preprocess_2(root_dir):\n",
    "    file_name = 'bcmk_data_position_expression_real_cells.csv'\n",
    "    sc_file_name = 'bcmk_sc_data_processed.txt'\n",
    "    bin_file_name = 'sc_isg_binarized.txt'\n",
    "    mcc_file_name = 'sc_is_mcc.npy'\n",
    "    pcc_file = 'pcc_pca20.npy'\n",
    "    df_sc_large = pd.read_csv(os.path.join(root_dir, 'counts.csv'), index_col=0).T\n",
    "    genes = df_sc_large.columns.values\n",
    "\n",
    "    # normalize\n",
    "    df = df_sc_large\n",
    "    x = np.array( df.values, float )\n",
    "    x = np.log( x + 1.0 )\n",
    "    for i in range(x.shape[1]):\n",
    "        if np.std(x[:,i]) == 0:\n",
    "            x[:, i] = 0.001\n",
    "        else:\n",
    "            x[:,i] = (x[:,i] - np.mean(x[:,i]))/np.std(x[:,i])\n",
    "    df_new = pd.DataFrame(data=x, columns=df.columns.values, index=df.index.values)\n",
    "    df_new.to_csv(os.path.join(root_dir, sc_file_name), sep='\\t')\n",
    "    df_sc_large.T.to_csv(os.path.join(root_dir, \"giotto_counts.txt\"), sep='\\t')\n",
    "    \n",
    "    pcc_mat = self_pcc_mat(x, progress=True)\n",
    "    np.save(os.path.join(root_dir, pcc_file), pcc_mat)\n",
    "    \n",
    "    df_sc = pd.read_csv(os.path.join(root_dir, sc_file_name), sep='\\t', index_col=0)\n",
    "    genes = df_sc.columns.values\n",
    "    sp_genes = genes\n",
    "    sp_genes = list(sp_genes)\n",
    "    x_sc = np.array( df_sc.values, float )\n",
    "    sc_genes = list( df_sc.columns.values )\n",
    "    gind = []\n",
    "    for g in sp_genes:\n",
    "        gind.append(sc_genes.index(g))\n",
    "    gind = np.array(gind, int)\n",
    "    x_sc = x_sc[:, gind]\n",
    "    df_sc_part = pd.DataFrame(data=x_sc, columns=sp_genes)\n",
    "    x_sc_bin = np.empty_like( x_sc )\n",
    "    for i in range(x_sc.shape[1]):\n",
    "        GM = GaussianMixture(n_components=2)\n",
    "        tmp = GM.fit_predict(x_sc[:,i].reshape(-1,1))\n",
    "        if GM.means_[0,0] > GM.means_[1,0]:\n",
    "            x_sc_bin[:,i] = 1.0 - tmp[:]\n",
    "        else:\n",
    "            x_sc_bin[:,i] = tmp[:]\n",
    "    df_sc_bin = pd.DataFrame(data=x_sc_bin, columns=sp_genes)\n",
    "    df_sc_bin.to_csv(os.path.join(root_dir, bin_file_name), sep='\\t')\n",
    "    \n",
    "    loc_data = pd.read_csv(os.path.join(root_dir, 'locs.csv'), index_col=0)\n",
    "    loc_data.to_csv(os.path.join(root_dir, 'spatalk_sc_st_data.csv'))\n",
    "    loc_data.to_csv(os.path.join(root_dir, 'giotto_loc.csv'), header=False, index=False)\n",
    "    \n",
    "    print('finish binarized', os.path.join(root_dir, bin_file_name))\n",
    "    sc_st_data = pd.read_csv(os.path.join(root_dir, 'spatalk_sc_st_data.csv'))\n",
    "    is_dmat_large =squareform(pdist(sc_st_data.loc[:, ['x', 'y']],metric='euclidean'))\n",
    "    print(is_dmat_large.shape)\n",
    "    sparse.save_npz(os.path.join(root_dir, 'is_mat.npz'), sparse.coo_matrix(is_dmat_large))\n",
    "    \n",
    "    mcc_all = np.asarray([get_mcc(p, g) for p in x_sc_bin for g in x_sc_bin])\n",
    "    mcc_all = mcc_all.reshape(len(x_sc_bin),-1)\n",
    "    np.save(os.path.join(root_dir, mcc_file_name), mcc_all)\n",
    "    \n",
    "\n",
    "def run(root_dir):\n",
    "    sc_st_data = pd.read_csv(os.path.join(root_dir, 'spatalk_sc_st_data.csv'))\n",
    "    is_dmat_large =squareform(pdist(sc_st_data.loc[:, ['x', 'y']],metric='euclidean'))\n",
    "    sparse.save_npz(os.path.join(root_dir, 'is_mat.npz'), sparse.coo_matrix(is_dmat_large))\n",
    "    df_sc = pd.read_csv(os.path.join(root_dir, 'bcmk_sc_data_processed.txt') , sep='\\t', index_col=0)\n",
    "    df_sc_bin = pd.read_csv(os.path.join(root_dir, 'sc_isg_binarized.txt'), sep='\\t', index_col=0)\n",
    "\n",
    "    df_is_bin = df_sc_bin\n",
    "    sc_pcc = np.load(os.path.join(root_dir, 'pcc_pca20.npy'))\n",
    "    mcc = np.load(os.path.join(root_dir, 'sc_is_mcc.npy'))\n",
    "    issc = SpaOTsc.spatial_sc(\n",
    "        sc_data=df_sc,\n",
    "        sc_data_bin=df_sc_bin,\n",
    "        is_data_bin=df_is_bin,\n",
    "        sc_dmat = np.exp(1-sc_pcc),\n",
    "        is_dmat=is_dmat_large)\n",
    "\n",
    "    issc.cell_cell_distance(sc_dmat_spatial=is_dmat_large)\n",
    "    issc.clustering(pca_n_components=2)\n",
    "    issc.nonspatial_correlation()\n",
    "    return issc\n",
    "    \n",
    "    \n",
    "def get_result(root_dir, issc):\n",
    "    lr_pair = pd.read_csv(os.path.join(root_dir, 'lrpair.csv')).loc[:, ['ligand', 'receptor']]\n",
    "    cell_info = pd.read_csv(os.path.join(root_dir, 'cell_info.csv'), index_col=0)\n",
    "    ct_num = len(np.unique(cell_info.loc[:, \"cell.type.idx\"].to_numpy()))\n",
    "    idx_dict = {}\n",
    "    for i in range(1, ct_num+1):\n",
    "        idx_dict[i] = cell_info['cell.type.idx'] == i\n",
    "    S_name_a_b = {}\n",
    "    for l, r in lr_pair.values.astype(str):\n",
    "        ccc = issc.spatial_signaling_ot([l], [r])\n",
    "        S_cluster_a_b = np.zeros([ct_num, ct_num], float)\n",
    "        for clusterA in range(1, ct_num+1):\n",
    "            for clusterB in range(1, ct_num+1):\n",
    "                idx_a = idx_dict[clusterA]\n",
    "                idx_b = idx_dict[clusterB]\n",
    "                C = ccc[idx_a,:][:,idx_b]\n",
    "                # take average of all cells from this cell-type pair in the score matrix from SpaOTsc\n",
    "                S_cluster_a_b[clusterA-1, clusterB-1] = np.mean(C)\n",
    "        S_name_a_b[f\"{l}-{r}\"] = S_cluster_a_b\n",
    "    col_name = ['CT'+str(i)+'-'+'CT'+str(j) for i in range(1, 6) for j in range(1, 6)]\n",
    "    spaot_rlt = pd.DataFrame(index=col_name)\n",
    "    for pre_pair in S_name_a_b.keys():\n",
    "        spaot_rlt[pre_pair] = S_name_a_b[pre_pair].reshape(-1)\n",
    "    spaot_rlt.T.to_csv(os.path.join(root_dir, 'spaot_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead5079-7415-4137-bdd3-4e2548a1842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = []\n",
    "\n",
    "for tree in [1, 3, 5]:\n",
    "    for ncell in [500, 800]:\n",
    "        for ngene in [110, 200, 500]:\n",
    "            for sigma in [0.1, 0.5]:\n",
    "                for seed in [1, 2, 3, 4]:\n",
    "                    root_dir = f\"~/scMultiSim/bench/unif/0/tree{tree}_{ncell}_cells{ngene}_genes_sigma{sigma}_{seed}/cci/\"\n",
    "                    dirs.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac2350-d960-4a59-857d-baba7b15e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root_dir in dirs:\n",
    "    preprocess_pathway(root_dir)\n",
    "    preprocess_2(root_dir)\n",
    "    issc = run(root_dir)\n",
    "    get_result(root_dir, issc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
